[{"title":"Jenkins获取代码及打包","date":"2018-01-17T07:30:13.743Z","path":"2018/01/17/Jenkins获取代码及打包方式/","text":"从tag中获取代码12345第一种方法：git parameter（需插件）；第二种方法：Repositories高级配置 - Name: ref - Refspec: +refs/tags/:refs/remotes/origin/tags/ - Branch Specifier(black for &apos;any&apos;): your _tag 打包指定的module123Build: - Root POM: pom.xml - Goals and options: -DskipTests -Ponline clean package -pl your-module -am","tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://yoursite.com/tags/Jenkins/"},{"name":"tag","slug":"tag","permalink":"http://yoursite.com/tags/tag/"},{"name":"package","slug":"package","permalink":"http://yoursite.com/tags/package/"}]},{"title":"日志收集","date":"2018-01-17T07:23:01.443Z","path":"2018/01/17/日志收集/","text":"logstash configlog4j 123456789101112131415161718input &#123; log4j &#123; mode =&gt; &quot;server&quot; host =&gt; &quot;0.0.0.0&quot; port =&gt; 4560 &#125; &#125; output&#123; stdout &#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt; [&quot;host1:9200&quot;] index =&gt; &quot;log4j-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;log4j_type&quot; &#125; &#125; logback 1234567891011121314151617input &#123; tcp &#123; port =&gt; 4560 codec =&gt; &quot;json&quot; &#125; &#125; output&#123; stdout &#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt; [&quot;localhost:9200&quot;] index =&gt; &quot;logback-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;logback_type&quot; &#125; &#125; log4j.properties12345log4j.rootLogger=debug,stdout,tcplog4j.appender.tcp=org.apache.log4j.net.SocketAppenderlog4j.appender.tcp.Port=4560log4j.appender.tcp.RemoteHost=localhostlog4j.appender.tcp.ReconnectionDelay=10000 logback.xml12345&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930&lt;appender name=&quot;STASH&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt; &lt;destination&gt;localhost:4560&lt;/destination&gt; &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt; &lt;providers&gt; &lt;!--&lt;mdc/&gt; &amp;lt;!&amp;ndash; MDC variables on the Thread will be written as JSON fields&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;context/&gt; &amp;lt;!&amp;ndash;Outputs entries from logback&apos;s context &amp;ndash;&amp;gt;--&gt; &lt;!--&lt;version/&gt; &amp;lt;!&amp;ndash; Logstash json format version, the @version field in the output&amp;ndash;&amp;gt;--&gt; &lt;logLevel/&gt; &lt;!--&lt;loggerName/&gt;--&gt; &lt;pattern&gt; &lt;pattern&gt; &#123; &quot;appName&quot;: &quot;yourappname&quot;, &quot;appVersion&quot;: &quot;1.0&quot; &#125; &lt;/pattern&gt; &lt;/pattern&gt; &lt;threadName/&gt; &lt;message/&gt; &lt;logstashMarkers/&gt; &lt;!-- Useful so we can add extra information for specific log lines as Markers--&gt; &lt;arguments/&gt; &lt;!--or through StructuredArguments--&gt; &lt;stackTrace/&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt;","tags":[{"name":"log4j","slug":"log4j","permalink":"http://yoursite.com/tags/log4j/"},{"name":"logback","slug":"logback","permalink":"http://yoursite.com/tags/logback/"},{"name":"logstash","slug":"logstash","permalink":"http://yoursite.com/tags/logstash/"}]},{"title":"线程池的运行机制","date":"2017-10-31T13:33:46.166Z","path":"2017/10/31/读书笔记-线程池的工作机制及原理/","text":"线程池的运行机制线程池的核心的两个队列： 现场等待池，即线程队列BlockingQueue。 任务处理池(PoolWoker)，即正在工作的Thread列表(HashSet )。 线程池的核心的参数： 核心池的大小(corePoolSize)，即固定大小，设定好之后，线程池的稳定峰值，达到这个值之后池的线程数大小不会释放的。 最大处理线程池数(maximumPoolSize)，当线程池里面的线程数超过corePoolSize，小于maximumPoolSize时会动态的创建与回收线程池里面的线程的资源。 我们举个例子来说明。假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的人做；当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待。 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来；然后将任务分配给这4个临时工人做。 如果说这14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中永远等待干活的10个工人机制就是workQueue。这个例子的corePoolSize就是10，而maximumPoolSize就是14 (10+4)。也就是说corePoolSize就是线程池的大小，maximumPoolSize在我看来就是线程池的一种补救措施，即任务量突然过大时的一种补救操作。 线程池参数详解 int corePoolSize: 核心池的大小。在创建线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThreads()方法，从这两个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就把到达的任务放到缓存队列当中。 int maximumPoolSize: 线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程；在corePoolSize和maximumPoolSize的线程数会被自动释放，而小于corePoolSize的不会。 long keepAliveTime: 表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0。 TimeUnit unit: 参数keepAliveTime的时间单位。 BlockingQueue workQueue: 一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响。 ThreadFactory threadFactory: 线程工厂，主要用来创建线程；可以是一个自定义过的现场工厂，默认是Executors.defaultThreadFactory()。 RejectedExecutionHandler handler: 表示当拒绝处理任务时的策略，也是可以自定义的，默认有4中取值： AbortPolicy（默认的）: 直接抛出异常 DiscardPolicy：不处理，丢弃掉 DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务 CallerRunsPolicy：只用调用者所在线程来运行任务","tags":[{"name":"线程池","slug":"线程池","permalink":"http://yoursite.com/tags/线程池/"},{"name":"ThreadPool","slug":"ThreadPool","permalink":"http://yoursite.com/tags/ThreadPool/"}]},{"title":"kafka源码走读之Producer send","date":"2017-10-20T07:05:07.138Z","path":"2017/10/20/kafka源码走读之Producer send/","text":"发送流程 获取meta信息(前面已讲) key, value序列化 计算发到哪个partition(如果key不为空, 则hash the keyBytes to choose a partition；否则随机一个数 n % numPrtitions，之后 (n++) % numPrtitions) 消息入队列，返回future(放入之后就返回，所以是异步，但是实际上可能还没有发送) sender线程从队列中获取消息batchs(批量), 然后sendProduceRequests(batches) 最终通过NIO模式发送（selector, bytebuffer, channel） 源码分析 123456789101112131415161718192021/** * Implementation of asynchronously send a record to a topic. */private Future&lt;RecordMetadata&gt; doSend(ProducerRecord&lt;K, V&gt; record, Callback callback) &#123; ... int partition = partition(record, serializedKey, serializedValue, cluster); int serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue); ensureValidRecordSize(serializedSize); tp = new TopicPartition(record.topic(), partition); long timestamp = record.timestamp() == null ? time.milliseconds() : record.timestamp(); log.trace(\"Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;\", record, callback, record.topic(), partition); // producer callback will make sure to call both 'callback' and interceptor callback Callback interceptCallback = this.interceptors == null ? callback : new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp); RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs); if (result.batchIsFull || result.newBatchCreated) &#123; log.trace(\"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch\", record.topic(), partition); this.sender.wakeup(); &#125; return result.future;&#125; RecordAccumulator使用双端队列存储RecordBatch，如果队列为空就新建一个RecordBatch；如果队列不为空（获取最后面的recordBatch），且recordBatch还有空间存放当前消息（每个recordBatch的默认大小为16M）。 12345678910111213141516171819202122232425262728293031323334353637383940/** * RecordAccumulator tryAppend * If `RecordBatch.tryAppend` fails (i.e. the record batch is full), close its memory records to release temporary * resources (like compression streams buffers). */private RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Callback callback, Deque&lt;RecordBatch&gt; deque) &#123; RecordBatch last = deque.peekLast(); if (last != null) &#123; FutureRecordMetadata future = last.tryAppend(timestamp, key, value, callback, time.milliseconds()); if (future == null) last.close(); else return new RecordAppendResult(future, deque.size() &gt; 1 || last.isFull(), false); &#125; return null;&#125;/** * RecordBatch tryAppend * Append the record to the current record set and return the relative offset within that record set * * @return The RecordSend corresponding to this record or null if there isn't sufficient room. */public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Callback callback, long now) &#123; if (!recordsBuilder.hasRoomFor(key, value)) &#123; return null; &#125; else &#123; long checksum = this.recordsBuilder.append(timestamp, key, value); this.maxRecordSize = Math.max(this.maxRecordSize, Record.recordSize(key, value)); this.lastAppendTime = now; FutureRecordMetadata future = new FutureRecordMetadata(this.produceFuture, this.recordCount, timestamp, checksum, key == null ? -1 : key.length, value == null ? -1 : value.length); if (callback != null) thunks.add(new Thunk(callback, future)); this.recordCount++; return future; &#125;&#125; Sender线程（run方法）从队列中获取batches，然后将batches封装成ClientRequest进行发送到channel。 1234567891011121314151617181920212223242526272829Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now);/** * Create a produce request from the given record batches */ private void sendProduceRequest(long now, int destination, short acks, int timeout, List&lt;RecordBatch&gt; batches) &#123; Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = new HashMap&lt;&gt;(batches.size()); final Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = new HashMap&lt;&gt;(batches.size()); for (RecordBatch batch : batches) &#123; TopicPartition tp = batch.topicPartition; produceRecordsByPartition.put(tp, batch.records()); recordsByPartition.put(tp, batch); &#125; ProduceRequest.Builder requestBuilder = new ProduceRequest.Builder(acks, timeout, produceRecordsByPartition); RequestCompletionHandler callback = new RequestCompletionHandler() &#123; public void onComplete(ClientResponse response) &#123; handleProduceResponse(response, recordsByPartition, time.milliseconds()); &#125; &#125;; String nodeId = Integer.toString(destination); ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0, callback); client.send(clientRequest, now); log.trace(\"Sent produce request to &#123;&#125;: &#123;&#125;\", nodeId, requestBuilder); &#125; NetworkClient将request封装成Send，并且保存到inFlightRequests（’在空中的request’）列表中；然后使用selector注册事件，对应的channel进行处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * NetworkClient doSend **/private void doSend(ClientRequest clientRequest, boolean isInternalRequest, long now) &#123; ... Send send = request.toSend(nodeId, header); InFlightRequest inFlightRequest = new InFlightRequest( header, clientRequest.createdTimeMs(), clientRequest.destination(), clientRequest.callback(), clientRequest.expectResponse(), isInternalRequest, send, now); this.inFlightRequests.add(inFlightRequest); selector.send(inFlightRequest.send);&#125;/** * Selector poll **/public void poll(long timeout) throws IOException &#123; ... if (readyKeys &gt; 0 || !immediatelyConnectedKeys.isEmpty()) &#123; pollSelectionKeys(this.nioSelector.selectedKeys(), false, endSelect); pollSelectionKeys(immediatelyConnectedKeys, true, endSelect); &#125; ...&#125;private void pollSelectionKeys(Iterable&lt;SelectionKey&gt; selectionKeys, boolean isImmediatelyConnected, long currentTimeNanos) &#123; Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); iterator.remove(); KafkaChannel channel = channel(key); ... /* if channel is ready read from any connections that have readable data */ if (channel.ready() &amp;&amp; key.isReadable() &amp;&amp; !hasStagedReceive(channel)) &#123; NetworkReceive networkReceive; while ((networkReceive = channel.read()) != null) addToStagedReceives(channel, networkReceive); &#125; /* if channel is ready write to any sockets that have space in their buffer and for which we have data */ if (channel.ready() &amp;&amp; key.isWritable()) &#123; Send send = channel.write(); if (send != null) &#123; this.completedSends.add(send); this.sensors.recordBytesSent(channel.id(), send.size()); &#125; &#125;&#125; //发送成功的request保存到completedReceives中private void addToCompletedReceives(KafkaChannel channel, Deque&lt;NetworkReceive&gt; stagedDeque) &#123; NetworkReceive networkReceive = stagedDeque.poll(); this.completedReceives.add(networkReceive); this.sensors.recordBytesReceived(channel.id(), networkReceive.payload().limit());&#125; NetworkClient的poll方法中会处理所有的responses 12345678910111213141516171819202122232425262728293031323334353637383940/** * Do actual reads and writes to sockets. * * @param timeout The maximum amount of time to wait (in ms) for responses if there are none immediately, * must be non-negative. The actual timeout will be the minimum of timeout, request timeout and * metadata timeout * @param now The current time in milliseconds * @return The list of responses received */@Overridepublic List&lt;ClientResponse&gt; poll(long timeout, long now) &#123; long metadataTimeout = metadataUpdater.maybeUpdate(now); try &#123; this.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs)); &#125; catch (IOException e) &#123; log.error(\"Unexpected error during I/O\", e); &#125; // process completed actions long updatedNow = this.time.milliseconds(); List&lt;ClientResponse&gt; responses = new ArrayList&lt;&gt;(); handleAbortedSends(responses); handleCompletedSends(responses, updatedNow); handleCompletedReceives(responses, updatedNow); handleDisconnections(responses, updatedNow); handleConnections(); handleInitiateApiVersionRequests(updatedNow); handleTimedOutRequests(responses, updatedNow); // invoke callbacks for (ClientResponse response : responses) &#123; try &#123; response.onComplete(); &#125; catch (Exception e) &#123; log.error(\"Uncaught error in request completion:\", e); &#125; &#125; return responses;&#125; 那么发送消息的时候是如何保证顺序发送的？答案是使用guaranteeMessageOrder（等于1就是有序的）。 RecordAccumulator使用Set集合来存储当前正在发送的TopicPartitions， 如果集合中存在该topicPartition，那么此时就不能发送该topicPartition对应的batches；直到completeBatchs时才移除该topicPartition。 1234567891011121314151617181920212223242526272829303132333435363738394041//Sender runvoid run(long now) &#123; ... Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now); if (guaranteeMessageOrder) &#123; // Mute all the partitions drained for (List&lt;RecordBatch&gt; batchList : batches.values()) &#123; for (RecordBatch batch : batchList) this.accumulator.mutePartition(batch.topicPartition); &#125; &#125;&#125;/** * Sender completeBatch * Complete or retry the given batch of records. * * @param batch The record batch * @param response The produce response * @param correlationId The correlation id for the request * @param now The current POSIX timestamp in milliseconds */private void completeBatch(RecordBatch batch, ProduceResponse.PartitionResponse response, long correlationId, long now) &#123; ... // Unmute the completed partition. if (guaranteeMessageOrder) this.accumulator.unmutePartition(batch.topicPartition);&#125;//RecordAccumulatorpublic void mutePartition(TopicPartition tp) &#123; muted.add(tp);&#125;public void unmutePartition(TopicPartition tp) &#123; muted.remove(tp);&#125;","tags":[{"name":"kafka","slug":"kafka","permalink":"http://yoursite.com/tags/kafka/"},{"name":"源码","slug":"源码","permalink":"http://yoursite.com/tags/源码/"}]},{"title":"kafka源码走读之Meta更新机制","date":"2017-10-20T03:43:23.737Z","path":"2017/10/20/kafka源码走读之Meta更新/","text":"kafka producer send消息前要先获取到meta信息；从meta信息中获取cluster信息，然后将消息发送到对应的partition； KafkaProducer获取Meta信息时会阻塞等待(wait)，直到meta信息更新(version+1)后才唤醒(notify)。 具体的request和response的处理都是在sender线程(ioThread)进行的： sender run方法会调用client.poll方法；NetworkClient.poll方法会判断meta信息是否需要更新，需要的话就发送request； 12public List&lt;ClientResponse&gt; poll(long timeout, long now) &#123; long metadataTimeout = metadataUpdater.maybeUpdate(now); request请求最终会变成Send对象, 并且放到KafkaChannel里；最终使用selector read/writer进行处理；获取到对应的response后进行处理（在NetworkClient里进行）； 123456789101112131415161718/** * Updates the cluster metadata. If topic expiry is enabled, expiry time * is set for topics if required and expired topics are removed from the metadata. * * @param cluster the cluster containing metadata for topics with valid metadata * @param unavailableTopics topics which are non-existent or have one or more partitions whose * leader is not known * @param now current time in milliseconds */ public synchronized void update(Cluster cluster, Set&lt;String&gt; unavailableTopics, long now) &#123; Objects.requireNonNull(cluster, \"cluster should not be null\"); this.needUpdate = false; this.lastRefreshMs = now; this.lastSuccessfulRefreshMs = now; this.version += 1; ... notifyAll(); //唤醒阻塞的所有线程 至此，获取meta信息的整个流程就是这样。","tags":[{"name":"kafka","slug":"kafka","permalink":"http://yoursite.com/tags/kafka/"},{"name":"源码","slug":"源码","permalink":"http://yoursite.com/tags/源码/"},{"name":"meta","slug":"meta","permalink":"http://yoursite.com/tags/meta/"}]},{"title":"Kafka设计解析","date":"2017-10-18T03:51:17.187Z","path":"2017/10/18/kafka设计解析/","text":"概述Kafka起初是由LinkedIn公司开发的一个分布式的消息系统，后成为Apache的一部分，它使用Scala编写，以可水平扩展和高吞吐率而被广泛使用。 Kafka与传统消息系统相比，有以下不同： 它被设计为一个分布式系统，易于向外扩展； 它同时为发布和订阅提供高吞吐； 它支持多订阅者，当失败时能自动平衡消费者； 它将消息持久化到磁盘，因此可用于批量消费以及实时应用程序。 Kafka体系架构： demo（java，Kafka-client 版本为0.10）12345678//producerProperties props = new Properties();props.put(\"bootstrap.servers\", \"localhost:9092\"); //kafka集群props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); //key序列化props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); //vlaue序列化Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);Future&lt;RecordMetadata&gt; future = producer.send(new ProducerRecord&lt;&gt;(topic, key, value)); //异步发送//RecordMetadata metadata = future.get(); //同步 123456789101112//consumerProperties props = new Properties();props.put(\"bootstrap.servers\", \"10.100.51.198:9092\");props.put(\"group.id\", \"my_group_id\");props.put(\"enable.auto.commit\", false);props.put(\"auto.commit.interval.ms\", \"1000\");props.put(\"session.timeout.ms\", \"30000\");props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);consumer.subscribe(Cpllection&lt;String&gt; topics);ConsumerRecords&lt;String, String&gt; records = consumer.poll(timeout);//拉取数据 各部分架构图Producer架构图 源码解读疑惑点 producer怎么实现异步发送消息？ producer发送消息如何保证顺序的？ consumer是单线程？ consumer offset如何控制的？","tags":[{"name":"kafka","slug":"kafka","permalink":"http://yoursite.com/tags/kafka/"},{"name":"架构","slug":"架构","permalink":"http://yoursite.com/tags/架构/"}]},{"title":"volatile关键字解析","date":"2017-10-13T08:58:54.245Z","path":"2017/10/13/volatile关键字解析/","text":"一、内存模型的相关概念计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，会涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）中的,这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢得多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了告诉缓存。 也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存中，那么CPU进行计算时就可以直接从他的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。比如下面的这段代码： i = i + 1 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。 这个代码在单线程中运行时没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行在不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。 比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2.但是事实是这样吗？ 可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作后，i的值为1，然后线程2吧i的值写入内存。 最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。 也就是说如果一个变量在多个CPU中都存在缓存（一个在多线程编程时才会出现），那么就有可能存在缓存一致性问题。 为了解决缓存不一致性问题，通常来说有以下2种解决方法： 1) 通过在总线加LOCK#锁的方式 2) 通过缓存一致性协议 这2种方式都是硬件层面上提供的方式。 在早期的CPU当中，是通过在总线上加LOCK#所得形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中如果一个线程在执行i=i+1，如果在执行这段代码的过程中，在总线上发出了LOCK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式有一个问题，由于在锁住中线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是Intel的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么他就会从内存中重新读取。 二、并发编程中的三个概念在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们看一下具体概念： 1. 原子性 原子性：即一个操作或多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 一个很经典的例子就是银行账户转账问题： 比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。 试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然终止。然后又从B中取出了500元，取出500元之后，再执行往账户B加上1000元操作。这样就会导致账户A虽然捡去了1000元，但是账户B没有收到这个转过来的1000元。 所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。 2. 可见性 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 举个简单的例子，看下嘛这段代码： //线程1执行的代码int i = 0;i = 10;//线程2执行的代码j = i; 假如执行线程1的是CPU1，执行线程2的是CPU2.由上面的分析可知，当线程1执行i=10这句时，会把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存中i的值变为10了，却没有立即写到主存中。 此时线程2执行j = i，他会先去主存读取i的值并加载到CPU2的缓存中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10。 这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。 3. 有序性 有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面的这段代码： int i = 0;boolean flag = false;i = 1;//语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1所在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。 下面解释一下什么是指令重排序，一般来说，处理器为了提高运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。 但是要注意，虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子： //线程1context = loadContext(); //语句1inited = true; //语句2 //线程2while(!inited) {sleep()}doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行中先执行了语句2，而此时线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 三、Java内存模型在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model, JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说就是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在Java内存模型中，也会存在缓存一致性问题和指令重排序问题。 Java内存模型规定所有的变量都是存在主存中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不是直接对主存进行操作。并亲每个线程不能访问其他线程的工作内存。 举个简单的例子：在java中，执行下面这个语句： i = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存进行赋值操作，然后再写入主存中。而不是直接将数值10写入主存当中。 那么Java语言本身对原子性、可见性以及有序性提供了哪些保证呢？ 1. 原子性 在Java中，对基本数据类型的变量的读取和赋值操作是员自行操作，即这些操作是不可被中断的，要么执行，要么不执行。 上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子： 请分析一下哪些操作是原子性操作： x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; 有些朋友可能会说上面的4个与剧中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句时会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及将x的值写入工作内存这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和x=x+1包含3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具有原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 不过这里有一点需要注意：在 32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值都是原子性操作了。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronize和Lock来实现。由于synchronize和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 2. 可见性 对于可见性，Java提供了volatile关键字来保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronize和lock也能保证可见性，synchronize和lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 3. 有序性 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的”有序性”。另外可以通过synchronize和Lock来保证有序性，很显然，synchronize和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的”有序性”， 即不需要通过任何手段就能够得到保证的有序性，这个通常也成为happens-before原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就具体介绍下happens-before原则（先行发生原则）： 12345678- 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作- 锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作- volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作- 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C- 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作- 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生- 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已终止执行- 对象终结规则：一个对象的初始化完成先行发生于它的finalize()方法的开始 这8条原则摘自《深入理解Java虚拟机》 这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。 下面我们来解释一下前4条规则： 对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到”书写在前面的操作先行发生于书写在后面的操作”， 这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证在单线程中执行结果的正确性，但是无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行释放操作，后面才能继续进行Lock操作。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 第四条规则实际上就是体现happens-before原则具备传递性。 四、深入剖析volatile关键字在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们进入主题。 1. volatile关键字的两层含义 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 1) 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 2) 禁止进行指令重排序 先看一段代码，假如线程1先执行，线程2后执行： //线程1boolean stop = false;while(!stop){ doSomething(); } //线程2stop = true; 这段代码是很经典的一段代码，很多人在中断线程时可能都会采用这种标记方法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断吗？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存中。 那么线程2更改了stop变量的值之后，但是还没来得及写入主存中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行失效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行失效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行失效，所以线程1再次读取stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 2. volatile保证原子性吗？ 从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？ 下面看一个例子： 12345678910111213141516171819public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for (int i=0; i&lt;10; i++) &#123; new Thread(() -&gt; &#123; for (int j=0; j&lt;1000; j++) &#123; test.increase(); &#125; &#125;).start(); &#125; while (Thread.activeCount() &gt; 1) Thread.yield(); System.out.println(test.inc); &#125;&#125; 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000.但是事实上运行它会发现每次运行结果都不一致，都是小于10000的数字。 可能有的朋友会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊。 这里有一个误区，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的值是最新的值，但是volatile没办法保证对变量的操作的原子性。 3. volatile能保证有序性吗？ 在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子： //x、y为非volatile变量//flag为volatile变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 那么我们回到前面举的一个例子： //线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited ){sleep()}doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 4.volatile的原理和实现机制 前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。","tags":[{"name":"volatile","slug":"volatile","permalink":"http://yoursite.com/tags/volatile/"}]}]